{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4e18dfa",
   "metadata": {},
   "source": [
    "# Scaling Computations using Parallel Computing\n",
    "\n",
    "## Przemysław Szufel and Julian Samaroo\n",
    "\n",
    "<a class=\"anchor\" id=\"toc\"></a>\n",
    "## Table of contents\n",
    "  \n",
    "\n",
    "1. [Multithreading](#multithreading)\n",
    "2. [Green threading](#green)\n",
    "3. [Multi-processing and distributed computing](#multiprocessing)\n",
    "4. [(background material) Parallelize via Single Instruction Multiple Data (SIMD)](#simd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dedff3-ed99-4fc7-9c08-f707e54c284c",
   "metadata": {},
   "source": [
    "Before running this Jupyter notebook, set Julia's configured number of threads.\n",
    "This should be done *before* actually running the `notebook()` command.\n",
    "The number of threads can be also set up in Julia options in Visual Studio code (if this is used to run this notebook).\n",
    "```\n",
    "# run this code from Julia REPL just before starting Jupyter Notebook\n",
    "ENV[\"JULIA_NUM_THREADS\"]=4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b0836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Number of threads that your Julia is running: $(Threads.nthreads()) threads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa1aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0561254",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"multithreading\"></a>\n",
    "### Multithreading\n",
    "---- [Return to table of contents](#toc) ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bf3161",
   "metadata": {},
   "source": [
    "Let's learn multithreading with a simple 2D sum example. Here's the serial (single CPU) code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "function ssum(x)\n",
    "    r, c = size(x)\n",
    "    y = zeros(c)\n",
    "    for j in 1:c\n",
    "        for i in 1:r\n",
    "            # Note how we index over dimension 1 in the inner loop; this is important for performance!\n",
    "            @inbounds y[j] += x[i, j]\n",
    "        end\n",
    "    end\n",
    "    y\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c03ee5f",
   "metadata": {},
   "source": [
    "And here's it modified for multithreading (multiple CPUs at once):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a4a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function tsum(x)\n",
    "    r, c = size(x)\n",
    "    y = zeros(c)\n",
    "    Threads.@threads for j in 1:c\n",
    "        for i in 1:r\n",
    "            @inbounds y[j] += x[i, j]\n",
    "        end\n",
    "    end\n",
    "    y\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe4d84c",
   "metadata": {},
   "source": [
    "How do they perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ebef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand(1000,10000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55526866",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time ssum(x)\n",
    "@time ssum(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed39ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time tsum(x)\n",
    "@time tsum(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba0e8e",
   "metadata": {},
   "source": [
    "For most people's computers, `tsum` should be a bit faster (but it won't be 4x faster, as you might expect!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d9f2a7",
   "metadata": {},
   "source": [
    "### Locking mechanism for threads\n",
    "\n",
    "When can you not do the same thing at the same time? Here's a bad multithreaded counter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5894cc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "function f_bad()\n",
    "    x = 0\n",
    "    Threads.@threads for i in 1:10^6\n",
    "        x += 1\n",
    "    end\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_bad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ec51d2",
   "metadata": {},
   "source": [
    "And here's the (fine) single-threaded counter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de164cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function f_add()\n",
    "    x = 0 \n",
    "    for i in 1:10^6\n",
    "        x += 1\n",
    "    end\n",
    "    x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ef96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_add()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ba2a4",
   "metadata": {},
   "source": [
    "Ehh, those values shouldn't be different! Why is that?\n",
    "\n",
    "Answer: `x += 1` isn't just one operation, it's 3! (read current x, increment value locally, write new x). On multiple threads, these might get misordered, leading to wrong results:\n",
    "\n",
    "x = 0\n",
    "\n",
    "T1: Read x (0)\n",
    "\n",
    "T2: Read x (0)\n",
    "\n",
    "T1: Increment local (1)\n",
    "\n",
    "T2: Increment local (1)\n",
    "\n",
    "T1: Write x (1)\n",
    "\n",
    "T2: Write x (1)\n",
    "\n",
    "So two increments became just one, uh oh!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb97516",
   "metadata": {},
   "outputs": [],
   "source": [
    "function f_atomic()\n",
    "    x = Threads.Atomic{Int}(0)\n",
    "    Threads.@threads for i in 1:10^6\n",
    "        Threads.atomic_add!(x, 1)\n",
    "    end\n",
    "    return x[]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ebcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_atomic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ee36ee",
   "metadata": {},
   "source": [
    "Yay, it works again! But is it fast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d9b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime f_add()\n",
    "@btime f_atomic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924cd0c",
   "metadata": {},
   "source": [
    "Hmmm, I guess it's actually not an improvement... Can we improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5359fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "function f_spin()\n",
    "    l = Threads.SpinLock()\n",
    "    x = Ref(0)\n",
    "    Threads.@threads for i in 1:10^6\n",
    "        Threads.lock(l) do\n",
    "            x[] += 1\n",
    "        end\n",
    "    end\n",
    "    return x[]\n",
    "end\n",
    "\n",
    "function f_reentrant()\n",
    "    l = ReentrantLock()\n",
    "    x = Ref(0)\n",
    "    Threads.@threads for i in 1:10^6\n",
    "        Threads.lock(l) do\n",
    "            x[] += 1\n",
    "        end\n",
    "    end\n",
    "    return x[]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert f_add() == f_atomic() == f_spin() == f_reentrant()\n",
    "\n",
    "@btime f_add()\n",
    "@btime f_atomic()\n",
    "@btime f_spin()\n",
    "@btime f_reentrant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e31c1c6",
   "metadata": {},
   "source": [
    "Well that's terrible! We have some lessons to learn:\n",
    "- Multithreading is easy to access in Julia, but;\n",
    "- ...multithreading isn't always a free performance win\n",
    "- The compiler makes single-CPU code go *really* fast (usually)\n",
    "- Correct multithreading can be surprisingly annoying and verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78a5296-8b54-475c-b5f2-9537ad26e663",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"green\"></a>\n",
    "### Green threading (multitasking)\n",
    "---- [Return to table of contents](#toc) ---\n",
    "\n",
    "How does Julia's multithreading work? Let's forget the \"multiple-CPU\" idea and just see a simpler concept, called \"multitasking\". When does sleeping for 4 seconds not take 4 seconds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da7625",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3275b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@time t = @async sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd7286e",
   "metadata": {},
   "source": [
    "This `@async` macro creates a `Task`, which runs the `sleep(2)` code in the \"background\". This lets us start some long-running code, and then do something else while it runs. Useful! How far does this \"background\" magic go?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function dojob(i)\n",
    "    val = round(rand(), digits=2)\n",
    "    sleep(val)   # this could be external computations with I/O\n",
    "    i, val\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Vector{Tuple{Int,Float64}}(undef, 8);\n",
    "@time for i=1:8\n",
    "    result[i] = dojob(i)\n",
    "end\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf5cf64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = Vector{Tuple{Int,Float64}}(undef, 8);\n",
    "@time for i=1:8\n",
    "   @async result[i] = dojob(i)\n",
    "end\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c7b724",
   "metadata": {},
   "source": [
    "Oops, that isn't right! Don't forget, just because something runs in the background, doesn't mean it also immediately completes. At some point we have to wait for it to finish!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc95ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Vector{Tuple{Int,Float64}}(undef, 8);\n",
    "@time @sync for i=1:8\n",
    "   @async result[i] = dojob(i)\n",
    "end\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7adf227",
   "metadata": {},
   "source": [
    "Very cool! And even cooler, Julia's multithreading is built on this idea. Unlike `@async` (which runs code on the same CPU where it's called), `Threads.@spawn` runs code on any available CPU that Julia has access to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Vector{Tuple{Int,Float64}}(undef, 8);\n",
    "@time @sync for i=1:8\n",
    "   Threads.@spawn result[i] = dojob(i)\n",
    "end\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2dfb6a",
   "metadata": {},
   "source": [
    "Of course, as we said before, multithreading doesn't always give free performance gains, but multitasking generally is a convenient way to do multiple things on the same CPU, or on different CPUs, with minimal effort from you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2846c599",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"multiprocessing\"></a>\n",
    "### Multi-processing and distributed computing\n",
    "--- [Return to table of contents](#toc) ---\n",
    "\n",
    "Now let's go beyond a single computer - what if we want to use multiple computers? Or what if we want to use one computer, but separate our tasks into different Julia processes? Then we can use Distributed.jl!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e7cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3b10c",
   "metadata": {},
   "source": [
    "This code adds 4 workers (and avoids adding more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0626f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "addprocs(max(0, 5-nprocs()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b678b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4457d5a",
   "metadata": {},
   "source": [
    "We've added some \"workers\" (independent Julia processes) on our local machine, which we can now control from IJulia/VSCode in many ways. Let's use the `@distributed` macro, which works similarly to the `Threads.@threads` macro (but for workers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffdc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "function s_rand()\n",
    "    n = 10^4\n",
    "    x = 0.0\n",
    "    for i in 1:n\n",
    "        x += sum(rand(10^4))\n",
    "    end\n",
    "    x / n\n",
    "end\n",
    " \n",
    "@time s_rand()\n",
    "@time s_rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ede908",
   "metadata": {},
   "outputs": [],
   "source": [
    "function p_rand()\n",
    "    n = 10^4\n",
    "    x = @distributed (+) for i in 1:n\n",
    "        # the last line will be aggregated\n",
    "        sum(rand(10^4))\n",
    "    end\n",
    "    x / n\n",
    "end\n",
    "\n",
    "@time p_rand()\n",
    "@time p_rand()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fade4ca",
   "metadata": {},
   "source": [
    "It's parallel, and it's actually fast! (Of course, this is a really simple problem to parallelize). Like multithreading, it's also possible to just spawn a single \"task\" with workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123009f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = @spawnat 3 4+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adea3cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf16de69",
   "metadata": {},
   "source": [
    "It's called a `Future`, but it's basically like a `Task`. By default, code runs on worker 1, but we can run code on any worker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74de87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "function myf() \n",
    "    println(\"I am on worker \", myid()) # myid() returns our current worker\n",
    "    rand()\n",
    "end\n",
    "myf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4599a69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = nothing\n",
    "try \n",
    "    fetch(@spawnat 4 myf())\n",
    "catch e\n",
    "    println(e)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3599b2",
   "metadata": {},
   "source": [
    "Oops! Code is also only evaluated on worker 1 by default, but we can use `@everywhere` to run code on all workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7658d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function myf() \n",
    "    println(\"I am on worker \", myid())\n",
    "    rand()\n",
    "end\n",
    "fetch(@spawnat 4 myf())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d208b0e",
   "metadata": {},
   "source": [
    "#### A typical pattern for setting an intial state across workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f281840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "@everywhere using Pkg\n",
    "@everywhere Pkg.activate(\".\")\n",
    "@everywhere using Distributed, Random, DataFrames\n",
    "\n",
    "@everywhere function calc(x, y)\n",
    "    2x + y\n",
    "end\n",
    "\n",
    "@everywhere function init_worker()    \n",
    "   Random.seed!(myid())\n",
    "    # reading initial data from files or other actions\n",
    "end\n",
    "\n",
    "@sync for wid in workers()\n",
    "    @async fetch(@spawnat wid init_worker())\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10189162",
   "metadata": {},
   "source": [
    "Typically results are collected to a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = @distributed (append!) for (i, j) = vec(collect(Iterators.product(1:4, 1:3)))\n",
    "    a = rand(1:499)\n",
    "    b = rand(1:9)*1000\n",
    "    c = calc(a, b)\n",
    "    DataFrame(;i,j,a,b,c,procid = myid())\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320ad9d4-78fb-4bfd-a192-e677d031b396",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"simd\"></a>\n",
    "### (background material) Parallelize via Single Instruction Multiple Data (SIMD)\n",
    "---- [Return to table of contents](#toc) ---\n",
    "\n",
    "A single CPU doesn't just have to do one thing at a time; with the power of SIMD, we can make our code faster by using parallelism built-in to CPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6acee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "function dot1(x, y)\n",
    "    s = 0.0\n",
    "    for i in 1:length(x)\n",
    "        @inbounds s += x[i]*y[i]\n",
    "    end\n",
    "    s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b35dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "function dot2(x, y)\n",
    "    s = 0.0\n",
    "    @simd for i in 1:length(x)\n",
    "        @inbounds s += x[i]*y[i]\n",
    "    end\n",
    "    s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693abf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 100*rand(10000)\n",
    "y = 100*rand(10000)\n",
    "\n",
    "@assert dot1(x, y) ≈ dot2(x, y)\n",
    "\n",
    "@btime dot1($x, $y)\n",
    "@btime dot2($x, $y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46ce92",
   "metadata": {},
   "source": [
    "Just beware that results aren't always exactly the same, due to floating point behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b64d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "@show dot1(x, y) dot2(x, y)\n",
    "@show dot1(x, y) == dot2(x, y)\n",
    "@show dot1(x, y) ≈ dot2(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040721cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
